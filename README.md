# Data-Quality-Monitoring

# Data Quality Monitoring Framework

This project delivers a modular data quality monitoring framework to detect, log, and alert on anomalies in pipeline outputs. It ensures reliability and trust in analytical datasets by embedding validation at key points.

## 🛠️ Technologies Used

- Apache Airflow
- Python
- Snowflake
- Power BI / Tableau
- SQL

## 🔍 Project Overview

As part of my work across roles:
- Developed rule-based and threshold-based data quality checks integrated into Airflow DAGs.
- Automated logging of anomalies and surfaced them in stakeholder dashboards using Power BI.
- Designed monitoring layers that tracked null rates, duplicate counts, and freshness SLAs.
- Collaborated with data governance teams to align monitoring logic with business rules.

## 📈 Business Impact

- Reduced downstream incidents by 30% by proactively catching schema mismatches and null anomalies.
- Enabled audit-ready data traceability and improved trust in analytics across departments.

